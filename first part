# ============================================
# DATA PREPROCESSING - INSURANCE COST PREDICTION
# ============================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import warnings
import joblib

warnings.filterwarnings('ignore')

# Load Dataset
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns")
print(df.head())

# Check Missing Values
missing_values = df.isnull().sum()
print(f"\nMissing values:\n{missing_values}")
if missing_values.sum() == 0:
    print("No missing values found!")

# Separate Features (X) and Target (y)
X = df.drop(columns=['charges'])
y = df['charges']
print(f"\nFeatures shape: {X.shape}, Target shape: {y.shape}")

# Train/Validation/Test Split (60/20/20)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

print(f"\nSplit Results:")
print(f"Training:   {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)")
print(f"Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(df)*100:.1f}%)")
print(f"Test:       {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)")

# Identify Column Types
numerical_cols = ['age', 'bmi', 'children']
categorical_cols = ['sex', 'smoker', 'region']
print(f"\nNumerical columns: {numerical_cols}")
print(f"Categorical columns: {categorical_cols}")

# Create Preprocessing Pipeline
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(drop='first'), categorical_cols)
])

# Fit and Transform Data
X_train_processed = preprocessor.fit_transform(X_train)
X_val_processed = preprocessor.transform(X_val)
X_test_processed = preprocessor.transform(X_test)

print(f"\nOriginal vs Processed Shapes:")
print(f"X_train: {X_train.shape} → {X_train_processed.shape}")
print(f"X_val:   {X_val.shape} → {X_val_processed.shape}")
print(f"X_test:  {X_test.shape} → {X_test_processed.shape}")

# Get Feature Names
cat_encoder = preprocessor.named_transformers_['cat']
cat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)
all_feature_names = list(numerical_cols) + list(cat_feature_names)
print(f"\nTotal features after preprocessing: {len(all_feature_names)}")

# K-Fold Cross-Validation Setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)
print(f"\n5-Fold Cross-Validation configured")

# Convert to arrays if needed
X_train_array = X_train_processed if isinstance(X_train_processed, np.ndarray) else X_train_processed.toarray()
X_val_array = X_val_processed if isinstance(X_val_processed, np.ndarray) else X_val_processed.toarray()
X_test_array = X_test_processed if isinstance(X_test_processed, np.ndarray) else X_test_processed.toarray()

# Save processed data
save_choice = 'y'
if save_choice == 'y':
    joblib.dump(preprocessor, 'preprocessor.pkl')
    
    np.savez('processed_data.npz',
             X_train=X_train_array,
             X_val=X_val_array,
             X_test=X_test_array,
             y_train=y_train.values,
             y_val=y_val.values,
             y_test=y_test.values,
             feature_names=all_feature_names)
    print("\nPreprocessor and data saved successfully!")

    # ============================================
# FEATURE IMPORTANCE & ANALYSIS
# ============================================

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
import warnings

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load or Use Processed Data
try:
    data = np.load('processed_data.npz', allow_pickle=True)
    X_train = data['X_train']
    y_train = data['y_train']
    feature_names = data['feature_names']
    print("Loaded saved processed data")
except:
    print("Using in-memory data (run preprocessing first)")

# Create DataFrame for Analysis
df_processed = pd.DataFrame(X_train, columns=feature_names)
df_processed['charges'] = y_train
print(f"\nProcessed DataFrame shape: {df_processed.shape}")

# Correlation Analysis
correlation_matrix = df_processed.corr()
correlation_with_target = correlation_matrix['charges'].sort_values(ascending=False)
print("\nCorrelation with target (charges):")
print(correlation_with_target.round(3))

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            fmt='.2f', square=True, cbar_kws={"shrink": 0.8})
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature Importance with Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

importances = rf_model.feature_importances_
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values('Importance', ascending=False)

print("\nFeature Importance Scores (Random Forest):")
print(feature_importance_df.round(4))

plt.figure(figsize=(10, 6))
bars = plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')
plt.xlabel('Importance Score')
plt.title('Random Forest Feature Importance')
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,
             f'{width:.3f}', ha='left', va='center')

plt.tight_layout()
plt.savefig('feature_importance_rf.png', dpi=300, bbox_inches='tight')
plt.show()

# Permutation Importance
perm_importance = permutation_importance(rf_model, X_train, y_train,
                                        n_repeats=10, random_state=42)

perm_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': perm_importance.importances_mean,
    'Std': perm_importance.importances_std
}).sort_values('Importance', ascending=False)

print("\nPermutation Importance (Mean ± Std):")
print(perm_importance_df.round(4))

plt.figure(figsize=(10, 6))
y_pos = np.arange(len(perm_importance_df))
plt.barh(y_pos, perm_importance_df['Importance'], 
         xerr=perm_importance_df['Std'], color='lightcoral', alpha=0.7)
plt.yticks(y_pos, perm_importance_df['Feature'])
plt.xlabel('Permutation Importance')
plt.title('Permutation Importance with Standard Deviation')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('permutation_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature Selection Decision
threshold = 0.01
low_importance_features = feature_importance_df[feature_importance_df['Importance'] < threshold]['Feature'].tolist()

if low_importance_features:
    print(f"\nFeatures with importance < {threshold}:")
    for feat in low_importance_features:
        importance = feature_importance_df[feature_importance_df['Feature'] == feat]['Importance'].values[0]
        print(f"  - {feat}: {importance:.4f}")
    print("\nRecommendation: Consider dropping these features for model simplicity")

# Feature Relationships Visualization
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Feature Relationships with Insurance Charges', fontsize=16, y=1.02)

# Age vs Charges
axes[0, 0].scatter(df['age'], df['charges'], alpha=0.5, color='blue')
axes[0, 0].set_xlabel('Age')
axes[0, 0].set_ylabel('Charges')
axes[0, 0].set_title('Age vs Charges')
axes[0, 0].grid(True, alpha=0.3)

# BMI vs Charges
axes[0, 1].scatter(df['bmi'], df['charges'], alpha=0.5, color='green')
axes[0, 1].set_xlabel('BMI')
axes[0, 1].set_ylabel('Charges')
axes[0, 1].set_title('BMI vs Charges')
axes[0, 1].grid(True, alpha=0.3)

# Smoker vs Charges
smoker_charges = [df[df['smoker'] == 'yes']['charges'], 
                  df[df['smoker'] == 'no']['charges']]
axes[0, 2].boxplot(smoker_charges, labels=['Smoker', 'Non-Smoker'])
axes[0, 2].set_ylabel('Charges')
axes[0, 2].set_title('Smoker vs Charges')
axes[0, 2].grid(True, alpha=0.3)

# Children vs Charges
axes[1, 0].boxplot([df[df['children'] == i]['charges'] for i in range(6)], 
                   labels=[str(i) for i in range(6)])
axes[1, 0].set_xlabel('Number of Children')
axes[1, 0].set_ylabel('Charges')
axes[1, 0].set_title('Children vs Charges')
axes[1, 0].grid(True, alpha=0.3)

# Sex vs Charges
sex_charges = [df[df['sex'] == 'female']['charges'], 
               df[df['sex'] == 'male']['charges']]
axes[1, 1].boxplot(sex_charges, labels=['Female', 'Male'])
axes[1, 1].set_ylabel('Charges')
axes[1, 1].set_title('Sex vs Charges')
axes[1, 1].grid(True, alpha=0.3)

# Region vs Charges
region_charges = [df[df['region'] == region]['charges'] for region in df['region'].unique()]
axes[1, 2].boxplot(region_charges, labels=df['region'].unique())
axes[1, 2].set_xlabel('Region')
axes[1, 2].set_ylabel('Charges')
axes[1, 2].set_title('Region vs Charges')
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('feature_relationships.png', dpi=300, bbox_inches='tight')
plt.show()
