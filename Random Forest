# RANDOM FOREST REGRESSOR

import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load and Prepare Data
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns")

# Feature Engineering
df['age_squared'] = df['age'] ** 2
df['bmi_squared'] = df['bmi'] ** 2
df['age_times_bmi'] = df['age'] * df['bmi'] / 100
df['smoker_age'] = df['age'] * (df['smoker'] == 'yes').astype(int)
df['smoker_bmi'] = df['bmi'] * (df['smoker'] == 'yes').astype(int)
df['is_obese'] = (df['bmi'] >= 30).astype(int)
df['is_overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)

print(f"Total features created: {df.shape[1] - 1}")

# Prepare Features and Target
X = df.drop(columns=['charges'])
y = df['charges']
categorical_cols = ['sex', 'smoker', 'region']
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
feature_names = X_encoded.columns.tolist()
print(f"Features after encoding: {len(feature_names)}")

# Log Transformation
y_log = np.log1p(y)
print(f"\nOriginal y range: ${y.min():,.2f} to ${y.max():,.2f}")

# Train/Validation/Test Split
X_train, X_temp, y_train_log, y_temp_log = train_test_split(
    X_encoded, y_log, test_size=0.4, random_state=42
)

X_val, X_test, y_val_log, y_test_log = train_test_split(
    X_temp, y_temp_log, test_size=0.5, random_state=42
)

y_train = np.expm1(y_train_log)
y_val = np.expm1(y_val_log)
y_test = np.expm1(y_test_log)

print(f"\nTraining: {X_train.shape[0]} samples")
print(f"Validation: {X_val.shape[0]} samples")
print(f"Test: {X_test.shape[0]} samples")

# Hyperparameter Optimization
param_grid = {
    'n_estimators': [300, 400, 500],
    'max_depth': [15, 20, 25, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [0.6, 0.8, None]
}

print("\nRunning hyperparameter optimization...")
grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42, n_jobs=-1),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=0
)

grid_search.fit(X_train, y_train_log)
print(f"Best parameters: {grid_search.best_params_}")

# Optimized Random Forest
best_rf = grid_search.best_estimator_
best_rf.fit(X_train, y_train_log)

# Predictions
y_train_pred_log = best_rf.predict(X_train)
y_val_pred_log = best_rf.predict(X_val)
y_test_pred_log = best_rf.predict(X_test)

y_train_pred = np.expm1(y_train_pred_log)
y_val_pred = np.expm1(y_val_pred_log)
y_test_pred = np.expm1(y_test_pred_log)

def print_metrics(y_true, y_pred, set_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    print(f"{set_name:12} MAE: ${mae:,.2f} | RMSE: ${rmse:,.2f} | R²: {r2:.4f}")
    return mae, rmse, r2

print("\nRANDOM FOREST PERFORMANCE:")
print("-" * 60)
train_mae, train_rmse, train_r2 = print_metrics(y_train, y_train_pred, "Training")
val_mae, val_rmse, val_r2 = print_metrics(y_val, y_val_pred, "Validation")
test_mae, test_rmse, test_r2 = print_metrics(y_test, y_test_pred, "Test")
print("-" * 60)

# Feature Importance
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_rf.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nTOP 10 FEATURES BY IMPORTANCE:")
print("-" * 45)
for i, row in importance_df.head(10).iterrows():
    print(f"{row['Feature']:25} {row['Importance']:.4f}")

plt.figure(figsize=(10, 6))
top_features = importance_df.head(15)
colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(top_features)))
bars = plt.barh(top_features['Feature'], top_features['Importance'], color=colors)
plt.xlabel('Importance Score')
plt.title('Random Forest Feature Importance')
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,
             f'{width:.3f}', ha='left', va='center')

plt.tight_layout()
plt.savefig('random_forest_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# Cross-Validation
cv_scores = cross_val_score(best_rf, X_train, y_train_log, 
                           cv=5, scoring='r2', n_jobs=-1)

print(f"\n5-FOLD CROSS-VALIDATION:")
print(f"Scores: {cv_scores.round(4)}")
print(f"Mean CV R²: {cv_scores.mean():.4f}")

# Visualizations
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].scatter(y_train, y_train_pred, alpha=0.5, color='blue', s=15)
max_val = max(y_train.max(), y_train_pred.max())
axes[0].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[0].set_xlabel('Actual Charges ($)')
axes[0].set_ylabel('Predicted Charges ($)')
axes[0].set_title(f'Training Set\nR² = {train_r2:.4f}')
axes[0].grid(True, alpha=0.3)

axes[1].scatter(y_val, y_val_pred, alpha=0.5, color='orange', s=15)
max_val = max(y_val.max(), y_val_pred.max())
axes[1].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[1].set_xlabel('Actual Charges ($)')
axes[1].set_ylabel('Predicted Charges ($)')
axes[1].set_title(f'Validation Set\nR² = {val_r2:.4f}')
axes[1].grid(True, alpha=0.3)

axes[2].scatter(y_test, y_test_pred, alpha=0.5, color='green', s=15)
max_val = max(y_test.max(), y_test_pred.max())
axes[2].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[2].set_xlabel('Actual Charges ($)')
axes[2].set_ylabel('Predicted Charges ($)')
axes[2].set_title(f'Test Set\nR² = {test_r2:.4f}')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('random_forest_predictions.png', dpi=300, bbox_inches='tight')
plt.show()

# Save Model
joblib.dump(best_rf, 'random_forest_model.pkl')
print("\nModel saved as 'random_forest_model.pkl'")

# Final Results
print("\n" + "=" * 60)
print("FINAL RESULTS")
print("=" * 60)
print(f"Test Set R² Score: {test_r2:.4f}")
print(f"Test Set MAE: ${test_mae:,.2f}")
print(f"Test Set RMSE: ${test_rmse:,.2f}")
print(f"5-Fold CV Mean R²: {cv_scores.mean():.4f}")
