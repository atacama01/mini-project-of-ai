# DATA PREPROCESSING - INSURANCE COST PREDICTION

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import warnings
import joblib

warnings.filterwarnings('ignore')

# Load Dataset
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns")
print(df.head())

# Check Missing Values
missing_values = df.isnull().sum()
print(f"\nMissing values:\n{missing_values}")
if missing_values.sum() == 0:
    print("No missing values found!")

# Separate Features (X) and Target (y)
X = df.drop(columns=['charges'])
y = df['charges']
print(f"\nFeatures shape: {X.shape}, Target shape: {y.shape}")

# Train/Validation/Test Split (60/20/20)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

print(f"\nSplit Results:")
print(f"Training:   {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)")
print(f"Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(df)*100:.1f}%)")
print(f"Test:       {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)")

# Identify Column Types
numerical_cols = ['age', 'bmi', 'children']
categorical_cols = ['sex', 'smoker', 'region']
print(f"\nNumerical columns: {numerical_cols}")
print(f"Categorical columns: {categorical_cols}")

# Create Preprocessing Pipeline
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(drop='first'), categorical_cols)
])

# Fit and Transform Data
X_train_processed = preprocessor.fit_transform(X_train)
X_val_processed = preprocessor.transform(X_val)
X_test_processed = preprocessor.transform(X_test)

print(f"\nOriginal vs Processed Shapes:")
print(f"X_train: {X_train.shape} → {X_train_processed.shape}")
print(f"X_val:   {X_val.shape} → {X_val_processed.shape}")
print(f"X_test:  {X_test.shape} → {X_test_processed.shape}")

# Get Feature Names
cat_encoder = preprocessor.named_transformers_['cat']
cat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)
all_feature_names = list(numerical_cols) + list(cat_feature_names)
print(f"\nTotal features after preprocessing: {len(all_feature_names)}")

# K-Fold Cross-Validation Setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)
print(f"\n5-Fold Cross-Validation configured")

# Convert to arrays if needed
X_train_array = X_train_processed if isinstance(X_train_processed, np.ndarray) else X_train_processed.toarray()
X_val_array = X_val_processed if isinstance(X_val_processed, np.ndarray) else X_val_processed.toarray()
X_test_array = X_test_processed if isinstance(X_test_processed, np.ndarray) else X_test_processed.toarray()

# Save processed data
save_choice = 'y'
if save_choice == 'y':
    joblib.dump(preprocessor, 'preprocessor.pkl')
    
    np.savez('processed_data.npz',
             X_train=X_train_array,
             X_val=X_val_array,
             X_test=X_test_array,
             y_train=y_train.values,
             y_val=y_val.values,
             y_test=y_test.values,
             feature_names=all_feature_names)
    print("\nPreprocessor and data saved successfully!")

# FEATURE IMPORTANCE & ANALYSIS

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load or Use Processed Data
try:
    data = np.load('processed_data.npz', allow_pickle=True)
    X_train = data['X_train']
    y_train = data['y_train']
    feature_names = data['feature_names']
    print("Loaded saved processed data")
except:
    print("Using in-memory data (run preprocessing first)")

# Create DataFrame for Analysis
df_processed = pd.DataFrame(X_train, columns=feature_names)
df_processed['charges'] = y_train
print(f"\nProcessed DataFrame shape: {df_processed.shape}")

# Correlation Analysis
correlation_matrix = df_processed.corr()
correlation_with_target = correlation_matrix['charges'].sort_values(ascending=False)
print("\nCorrelation with target (charges):")
print(correlation_with_target.round(3))

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            fmt='.2f', square=True, cbar_kws={"shrink": 0.8})
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature Importance with Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

importances = rf_model.feature_importances_
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values('Importance', ascending=False)

print("\nFeature Importance Scores (Random Forest):")
print(feature_importance_df.round(4))

plt.figure(figsize=(10, 6))
bars = plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')
plt.xlabel('Importance Score')
plt.title('Random Forest Feature Importance')
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,
             f'{width:.3f}', ha='left', va='center')

plt.tight_layout()
plt.savefig('feature_importance_rf.png', dpi=300, bbox_inches='tight')
plt.show()

# Permutation Importance
perm_importance = permutation_importance(rf_model, X_train, y_train,
                                        n_repeats=10, random_state=42)

perm_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': perm_importance.importances_mean,
    'Std': perm_importance.importances_std
}).sort_values('Importance', ascending=False)

print("\nPermutation Importance (Mean ± Std):")
print(perm_importance_df.round(4))

plt.figure(figsize=(10, 6))
y_pos = np.arange(len(perm_importance_df))
plt.barh(y_pos, perm_importance_df['Importance'], 
         xerr=perm_importance_df['Std'], color='lightcoral', alpha=0.7)
plt.yticks(y_pos, perm_importance_df['Feature'])
plt.xlabel('Permutation Importance')
plt.title('Permutation Importance with Standard Deviation')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('permutation_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature Selection Decision
threshold = 0.01
low_importance_features = feature_importance_df[feature_importance_df['Importance'] < threshold]['Feature'].tolist()

if low_importance_features:
    print(f"\nFeatures with importance < {threshold}:")
    for feat in low_importance_features:
        importance = feature_importance_df[feature_importance_df['Feature'] == feat]['Importance'].values[0]
        print(f"  - {feat}: {importance:.4f}")
    print("\nRecommendation: Consider dropping these features for model simplicity")

# Feature Relationships Visualization
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Feature Relationships with Insurance Charges', fontsize=16, y=1.02)

# Age vs Charges
axes[0, 0].scatter(df['age'], df['charges'], alpha=0.5, color='blue')
axes[0, 0].set_xlabel('Age')
axes[0, 0].set_ylabel('Charges')
axes[0, 0].set_title('Age vs Charges')
axes[0, 0].grid(True, alpha=0.3)

# BMI vs Charges
axes[0, 1].scatter(df['bmi'], df['charges'], alpha=0.5, color='green')
axes[0, 1].set_xlabel('BMI')
axes[0, 1].set_ylabel('Charges')
axes[0, 1].set_title('BMI vs Charges')
axes[0, 1].grid(True, alpha=0.3)

# Smoker vs Charges
smoker_charges = [df[df['smoker'] == 'yes']['charges'], 
                  df[df['smoker'] == 'no']['charges']]
axes[0, 2].boxplot(smoker_charges, labels=['Smoker', 'Non-Smoker'])
axes[0, 2].set_ylabel('Charges')
axes[0, 2].set_title('Smoker vs Charges')
axes[0, 2].grid(True, alpha=0.3)

# Children vs Charges
axes[1, 0].boxplot([df[df['children'] == i]['charges'] for i in range(6)], 
                   labels=[str(i) for i in range(6)])
axes[1, 0].set_xlabel('Number of Children')
axes[1, 0].set_ylabel('Charges')
axes[1, 0].set_title('Children vs Charges')
axes[1, 0].grid(True, alpha=0.3)

# Sex vs Charges
sex_charges = [df[df['sex'] == 'female']['charges'], 
               df[df['sex'] == 'male']['charges']]
axes[1, 1].boxplot(sex_charges, labels=['Female', 'Male'])
axes[1, 1].set_ylabel('Charges')
axes[1, 1].set_title('Sex vs Charges')
axes[1, 1].grid(True, alpha=0.3)

# Region vs Charges
region_charges = [df[df['region'] == region]['charges'] for region in df['region'].unique()]
axes[1, 2].boxplot(region_charges, labels=df['region'].unique())
axes[1, 2].set_xlabel('Region')
axes[1, 2].set_ylabel('Charges')
axes[1, 2].set_title('Region vs Charges')
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('feature_relationships.png', dpi=300, bbox_inches='tight')
plt.show()

# NEURAL NETWORK

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


warnings.filterwarnings('ignore')
torch.manual_seed(42)
np.random.seed(42)

# Load ORIGINAL Data and Apply Feature Engineering
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Original data loaded: {df.shape[0]} rows, {df.shape[1]} columns")

# FEATURE ENGINEERING
df['age_squared'] = df['age'] ** 2
df['bmi_squared'] = df['bmi'] ** 2
df['age_times_bmi'] = df['age'] * df['bmi'] / 100
df['smoker_age'] = df['age'] * (df['smoker'] == 'yes').astype(int)
df['smoker_bmi'] = df['bmi'] * (df['smoker'] == 'yes').astype(int)
df['risk_score'] = df['age']/10 + df['bmi']/5 + df['children']*2
df['is_obese'] = (df['bmi'] >= 30).astype(int)
df['is_overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)
df['age_group'] = pd.cut(df['age'], 
                        bins=[18, 30, 40, 50, 60, 65],
                        labels=['18-29', '30-39', '40-49', '50-59', '60+'])
df['children_age'] = df['children'] * df['age'] / 10

print(f"Total features after engineering: {df.shape[1] - 1} (excluding charges)")

# Split into X and y
X = df.drop(columns=['charges'])
y = df['charges']
print(f"X shape: {X.shape}, y shape: {y.shape}")

# Train/Validation/Test Split (60/20/20)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

print(f"\nTraining: {X_train.shape[0]} samples")
print(f"Validation: {X_val.shape[0]} samples")
print(f"Test: {X_test.shape[0]} samples")

# Preprocessing with NEW features
numerical_cols = ['age', 'bmi', 'children', 'age_squared', 'bmi_squared', 
                  'age_times_bmi', 'smoker_age', 'smoker_bmi', 'risk_score',
                  'is_obese', 'is_overweight', 'children_age']
categorical_cols = ['sex', 'smoker', 'region', 'age_group']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)
])

X_train_processed = preprocessor.fit_transform(X_train)
X_val_processed = preprocessor.transform(X_val)
X_test_processed = preprocessor.transform(X_test)

cat_encoder = preprocessor.named_transformers_['cat']
cat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)
all_feature_names = list(numerical_cols) + list(cat_feature_names)

print(f"\nOriginal X_train shape: {X_train.shape}")
print(f"Processed X_train shape: {X_train_processed.shape}")
print(f"Total features after preprocessing: {len(all_feature_names)}")

# SCALE THE TARGET VARIABLE
y_scaler = StandardScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_val_scaled = y_scaler.transform(y_val.values.reshape(-1, 1)).flatten()
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()

print(f"\nOriginal y range: ${y_train.min():,.2f} to ${y_train.max():,.2f}")
print(f"Scaled y range: {y_train_scaled.min():.3f} to {y_train_scaled.max():.3f}")

# Convert to PyTorch Tensors
X_train_tensor = torch.FloatTensor(X_train_processed)
y_train_tensor = torch.FloatTensor(y_train_scaled).reshape(-1, 1)
X_val_tensor = torch.FloatTensor(X_val_processed)
y_val_tensor = torch.FloatTensor(y_val_scaled).reshape(-1, 1)
X_test_tensor = torch.FloatTensor(X_test_processed)
y_test_tensor = torch.FloatTensor(y_test_scaled).reshape(-1, 1)

print(f"\nInput size: {X_train_tensor.shape[1]} features")
print(f"Training samples: {X_train_tensor.shape[0]}")

# Create DataLoader
batch_size = 32
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# NEURAL NETWORK ARCHITECTURE
class EnhancedInsuranceNet(nn.Module):
    def __init__(self, input_size):
        super(EnhancedInsuranceNet, self).__init__()
        self.layer1 = nn.Linear(input_size, 64)
        self.bn1 = nn.BatchNorm1d(64)
        self.drop1 = nn.Dropout(0.3)
        self.layer2 = nn.Linear(64, 32)
        self.bn2 = nn.BatchNorm1d(32)
        self.drop2 = nn.Dropout(0.2)
        self.layer3 = nn.Linear(32, 16)
        self.bn3 = nn.BatchNorm1d(16)
        self.output = nn.Linear(16, 1)
        self._initialize_weights()
    
    def _initialize_weights(self):
        for layer in [self.layer1, self.layer2, self.layer3, self.output]:
            if isinstance(layer, nn.Linear):
                nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
    
    def forward(self, x):
        out = self.layer1(x)
        out = self.bn1(out)
        out = torch.relu(out)
        out = self.drop1(out)
        out = self.layer2(out)
        out = self.bn2(out)
        out = torch.relu(out)
        out = self.drop2(out)
        out = self.layer3(out)
        out = self.bn3(out)
        out = torch.relu(out)
        out = self.output(out)
        return out

input_size = X_train_tensor.shape[1]
model = EnhancedInsuranceNet(input_size)
print(f"\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}")

# TRAINING SETUP
criterion = nn.HuberLoss(delta=1.0)
optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-3)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6, verbose=False
)

# TRAINING FUNCTIONS
def train_epoch_enhanced(model, loader, criterion, optimizer):
    model.train()
    total_loss = 0
    for batch_x, batch_y in loader:
        optimizer.zero_grad()
        predictions = model(batch_x)
        loss = criterion(predictions, batch_y)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def validate_enhanced(model, loader, criterion):
    model.eval()
    total_loss = 0
    all_predictions = []
    all_targets = []
    with torch.no_grad():
        for batch_x, batch_y in loader:
            predictions = model(batch_x)
            loss = criterion(predictions, batch_y)
            total_loss += loss.item()
            all_predictions.extend(predictions.cpu().numpy())
            all_targets.extend(batch_y.cpu().numpy())
    return total_loss / len(loader), np.array(all_predictions), np.array(all_targets)

# TRAINING LOOP
num_epochs = 200
patience = 30
best_val_loss = float('inf')
patience_counter = 0
train_losses = []
val_losses = []

print(f"\nTraining for {num_epochs} epochs (patience={patience})...")

for epoch in range(num_epochs):
    train_loss = train_epoch_enhanced(model, train_loader, criterion, optimizer)
    train_losses.append(train_loss)
    
    val_loss, val_preds_scaled, val_targets_scaled = validate_enhanced(model, val_loader, criterion)
    val_losses.append(val_loss)
    
    scheduler.step(val_loss)
    
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_loss': val_loss,
            'y_scaler_mean': y_scaler.mean_,
            'y_scaler_scale': y_scaler.scale_
        }, 'enhanced_best_nn_model.pth')
    else:
        patience_counter += 1
    
    if (epoch + 1) % 20 == 0:
        print(f"Epoch [{epoch+1:3d}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
    
    if patience_counter >= patience:
        print(f"\nEarly stopping triggered at epoch {epoch+1}")
        break

print(f"\nTraining completed! Best validation loss: {best_val_loss:.4f}")

# EVALUATION
def inverse_transform_predictions(model, loader, y_scaler):
    model.eval()
    all_preds_scaled = []
    all_targets_scaled = []
    with torch.no_grad():
        for batch_x, batch_y in loader:
            preds = model(batch_x)
            all_preds_scaled.extend(preds.cpu().numpy())
            all_targets_scaled.extend(batch_y.cpu().numpy())
    
    preds_scaled = np.array(all_preds_scaled).reshape(-1, 1)
    targets_scaled = np.array(all_targets_scaled).reshape(-1, 1)
    preds_original = y_scaler.inverse_transform(preds_scaled).flatten()
    targets_original = y_scaler.inverse_transform(targets_scaled).flatten()
    return preds_original, targets_original

train_preds, train_targets = inverse_transform_predictions(model, train_loader, y_scaler)
val_preds, val_targets = inverse_transform_predictions(model, val_loader, y_scaler)
test_preds, test_targets = inverse_transform_predictions(model, test_loader, y_scaler)

def calculate_all_metrics(predictions, targets):
    mae = mean_absolute_error(targets, predictions)
    rmse = np.sqrt(mean_squared_error(targets, predictions))
    r2 = r2_score(targets, predictions)
    mape = np.mean(np.abs((targets - predictions) / np.clip(targets, 1e-10, None))) * 100
    return mae, rmse, r2, mape

train_mae, train_rmse, train_r2, train_mape = calculate_all_metrics(train_preds, train_targets)
val_mae, val_rmse, val_r2, val_mape = calculate_all_metrics(val_preds, val_targets)
test_mae, test_rmse, test_r2, test_mape = calculate_all_metrics(test_preds, test_targets)

print("\nPERFORMANCE METRICS:")
print(f"{'Set':<15} {'MAE ($)':<12} {'RMSE ($)':<12} {'R² Score':<10}")
print("-" * 50)
print(f"{'Training':<15} {train_mae:,.2f}{'':<2} {train_rmse:,.2f}{'':<2} {train_r2:.4f}")
print(f"{'Validation':<15} {val_mae:,.2f}{'':<2} {val_rmse:,.2f}{'':<2} {val_r2:.4f}")
print(f"{'Test':<15} {test_mae:,.2f}{'':<2} {test_rmse:,.2f}{'':<2} {test_r2:.4f}")

# VISUALIZATION
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Training history
axes[0, 0].plot(train_losses, label='Training Loss', linewidth=2, color='blue')
axes[0, 0].plot(val_losses, label='Validation Loss', linewidth=2, color='red')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss (Huber)')
axes[0, 0].set_title('Training History')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Training set predictions
axes[0, 1].scatter(train_targets, train_preds, alpha=0.5, color='blue', s=10)
max_val = max(train_targets.max(), train_preds.max())
axes[0, 1].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[0, 1].set_xlabel('Actual Charges ($)')
axes[0, 1].set_ylabel('Predicted Charges ($)')
axes[0, 1].set_title(f'Training Set\nR² = {train_r2:.4f}')
axes[0, 1].grid(True, alpha=0.3)

# Validation set predictions
axes[0, 2].scatter(val_targets, val_preds, alpha=0.5, color='orange', s=10)
max_val = max(val_targets.max(), val_preds.max())
axes[0, 2].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[0, 2].set_xlabel('Actual Charges ($)')
axes[0, 2].set_ylabel('Predicted Charges ($)')
axes[0, 2].set_title(f'Validation Set\nR² = {val_r2:.4f}')
axes[0, 2].grid(True, alpha=0.3)

# Test set predictions
axes[1, 0].scatter(test_targets, test_preds, alpha=0.5, color='green', s=10)
max_val = max(test_targets.max(), test_preds.max())
axes[1, 0].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[1, 0].set_xlabel('Actual Charges ($)')
axes[1, 0].set_ylabel('Predicted Charges ($)')
axes[1, 0].set_title(f'Test Set\nR² = {test_r2:.4f}')
axes[1, 0].grid(True, alpha=0.3)

# Performance summary
summary_text = f"""FINAL PERFORMANCE
Test Set:
• R² Score: {test_r2:.4f}
• MAE: ${test_mae:,.0f}
• RMSE: ${test_rmse:,.0f}
• MAPE: {test_mape:.1f}%"""

axes[1, 1].text(0.5, 0.5, summary_text, 
                ha='center', va='center', fontsize=12,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
axes[1, 1].axis('off')
axes[1, 1].set_title('Performance Summary')

plt.tight_layout()
plt.savefig('enhanced_nn_results.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"\nFINAL PERFORMANCE (Test Set):")
print(f"R² Score: {test_r2:.4f}")
print(f"MAE: ${test_mae:,.2f}")
print(f"RMSE: ${test_rmse:,.2f}")

# DECISION TREE REGRESSOR

from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.ensemble import BaggingRegressor

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load and Prepare Data
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns")

# ENHANCED FEATURE ENGINEERING FOR BETTER PERFORMANCE
df['age_squared'] = df['age'] ** 2
df['bmi_squared'] = df['bmi'] ** 2
df['age_times_bmi'] = df['age'] * df['bmi'] / 100
df['smoker_age'] = df['age'] * (df['smoker'] == 'yes').astype(int)
df['smoker_bmi'] = df['bmi'] * (df['smoker'] == 'yes').astype(int)
df['is_obese'] = (df['bmi'] >= 30).astype(int)
df['is_overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)
df['children_interaction'] = df['children'] * df['age'] / 10
df['bmi_age_ratio'] = df['bmi'] / (df['age'] + 1)
df['risk_score'] = df['age']/10 + df['bmi']/5 + df['children']*2
df['log_age'] = np.log(df['age'] + 1)
df['log_bmi'] = np.log(df['bmi'] + 1)

print(f"Total features created: {df.shape[1] - 1}")

# Prepare Features and Target
X = df.drop(columns=['charges'])
y = df['charges']
categorical_cols = ['sex', 'smoker', 'region']
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
feature_names = X_encoded.columns.tolist()
print(f"Features after encoding: {len(feature_names)}")

# APPLY LOG TRANSFORMATION TO TARGET (IMPORTANT FOR TREE MODELS)
y_log = np.log1p(y)  # log(1 + y)
print(f"\nOriginal y range: ${y.min():,.2f} to ${y.max():,.2f}")
print(f"Log-transformed y range: {y_log.min():.3f} to {y_log.max():.3f}")

# Train/Validation/Test Split (60/20/20) with log target
X_train, X_temp, y_train_log, y_temp_log = train_test_split(
    X_encoded, y_log, test_size=0.4, random_state=42
)

X_val, X_test, y_val_log, y_test_log = train_test_split(
    X_temp, y_temp_log, test_size=0.5, random_state=42
)

# Convert back to original scale for metrics
y_train = np.expm1(y_train_log)
y_val = np.expm1(y_val_log)
y_test = np.expm1(y_test_log)

print(f"\nTraining: {X_train.shape[0]} samples")
print(f"Validation: {X_val.shape[0]} samples")
print(f"Test: {X_test.shape[0]} samples")

# ENHANCED HYPERPARAMETER OPTIMIZATION FOR HIGHER R²
param_grid = {
    'max_depth': [8, 10, 12, 15, None],
    'min_samples_split': [2, 3, 4, 5],
    'min_samples_leaf': [1, 2, 3, 4],
    'max_features': [0.6, 0.7, 0.8, 0.9, None],
    'ccp_alpha': [0.0, 0.001, 0.01, 0.1]
}

print("\nRunning enhanced hyperparameter optimization...")
grid_search = GridSearchCV(
    DecisionTreeRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=0
)

grid_search.fit(X_train, y_train_log)
print(f"Optimization completed")
print(f"Best parameters: {grid_search.best_params_}")

# OPTIMIZED DECISION TREE (Trained on log-transformed target)
best_dt = grid_search.best_estimator_
best_dt.fit(X_train, y_train_log)

# Predict on log scale, then convert back
y_train_pred_log = best_dt.predict(X_train)
y_val_pred_log = best_dt.predict(X_val)
y_test_pred_log = best_dt.predict(X_test)

# Convert back to original scale
y_train_pred = np.expm1(y_train_pred_log)
y_val_pred = np.expm1(y_val_pred_log)
y_test_pred = np.expm1(y_test_pred_log)

def print_metrics(y_true, y_pred, set_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    print(f"{set_name:12} MAE: ${mae:,.2f} | RMSE: ${rmse:,.2f} | R²: {r2:.4f}")
    return mae, rmse, r2

print("\n ENHANCED PERFORMANCE (with log transformation):")
print("-" * 60)
train_mae, train_rmse, train_r2 = print_metrics(y_train, y_train_pred, "Training")
val_mae, val_rmse, val_r2 = print_metrics(y_val, y_val_pred, "Validation")
test_mae, test_rmse, test_r2 = print_metrics(y_test, y_test_pred, "Test")
print("-" * 60)

# BAGGING ENSEMBLE FOR FURTHER IMPROVEMENT
print("\n Applying Bagging Ensemble for additional boost...")
bagging_dt = BaggingRegressor(
    estimator=DecisionTreeRegressor(
        max_depth=best_dt.max_depth if hasattr(best_dt, 'max_depth') else None,
        min_samples_split=best_dt.min_samples_split if hasattr(best_dt, 'min_samples_split') else 2,
        min_samples_leaf=best_dt.min_samples_leaf if hasattr(best_dt, 'min_samples_leaf') else 1,
        random_state=42
    ),
    n_estimators=50,
    max_samples=0.8,
    max_features=0.8,
    bootstrap=True,
    n_jobs=-1,
    random_state=42
)

bagging_dt.fit(X_train, y_train_log)
y_test_pred_bagging_log = bagging_dt.predict(X_test)
y_test_pred_bagging = np.expm1(y_test_pred_bagging_log)

test_r2_bagging = r2_score(y_test, y_test_pred_bagging)
test_mae_bagging = mean_absolute_error(y_test, y_test_pred_bagging)

print(f"Bagging Ensemble R²: {test_r2_bagging:.4f}")
print(f"Bagging Ensemble MAE: ${test_mae_bagging:,.2f}")

# Use the better model
if test_r2_bagging > test_r2:
    final_r2 = test_r2_bagging
    final_mae = test_mae_bagging
    final_pred = y_test_pred_bagging
    print(" Using Bagging Ensemble (better performance)")
else:
    final_r2 = test_r2
    final_mae = test_mae
    final_pred = y_test_pred
    print(" Using single Decision Tree (better performance)")

# FEATURE IMPORTANCE ANALYSIS
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_dt.feature_importances_
}).sort_values('Importance', ascending=False)

print("\n TOP 10 MOST IMPORTANT FEATURES:")
print("-" * 45)
for i, row in importance_df.head(10).iterrows():
    print(f"{row['Feature']:30} {row['Importance']:.4f}")

# Visualize feature importance
plt.figure(figsize=(12, 8))
top_features = importance_df.head(15)
colors = plt.cm.plasma(np.linspace(0.2, 0.9, len(top_features)))
bars = plt.barh(top_features['Feature'], top_features['Importance'], color=colors)
plt.xlabel('Importance Score', fontsize=12, fontweight='bold')
plt.title('Enhanced Decision Tree Feature Importance', fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,
             f'{width:.4f}', ha='left', va='center', fontsize=10)

plt.tight_layout()
plt.savefig('enhanced_decision_tree_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# CROSS-VALIDATION ANALYSIS
cv_scores = cross_val_score(best_dt, X_train, y_train_log, 
                           cv=5, scoring='r2', n_jobs=-1)

print(f"\n 5-FOLD CROSS-VALIDATION:")
print(f"Scores: {cv_scores.round(4)}")
print(f"Mean CV R²: {cv_scores.mean():.4f}")
print(f"Std Deviation: {cv_scores.std():.4f}")

# FINAL EVALUATION
print("\n" + "=" * 60)
print(" FINAL MODEL EVALUATION")
print("=" * 60)

print(f"Test Set R² Score: {final_r2:.4f}")
print(f"Test Set MAE: ${final_mae:,.2f}")

# Save the model
joblib.dump(best_dt, 'enhanced_decision_tree_model.pkl')

# RANDOM FOREST REGRESSOR

import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load and Prepare Data
df = pd.read_csv('/kaggle/input/insurance/insurance.csv')
print(f"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns")

# Feature Engineering
df['age_squared'] = df['age'] ** 2
df['bmi_squared'] = df['bmi'] ** 2
df['age_times_bmi'] = df['age'] * df['bmi'] / 100
df['smoker_age'] = df['age'] * (df['smoker'] == 'yes').astype(int)
df['smoker_bmi'] = df['bmi'] * (df['smoker'] == 'yes').astype(int)
df['is_obese'] = (df['bmi'] >= 30).astype(int)
df['is_overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)

print(f"Total features created: {df.shape[1] - 1}")

# Prepare Features and Target
X = df.drop(columns=['charges'])
y = df['charges']
categorical_cols = ['sex', 'smoker', 'region']
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
feature_names = X_encoded.columns.tolist()
print(f"Features after encoding: {len(feature_names)}")

# Log Transformation
y_log = np.log1p(y)
print(f"\nOriginal y range: ${y.min():,.2f} to ${y.max():,.2f}")

# Train/Validation/Test Split
X_train, X_temp, y_train_log, y_temp_log = train_test_split(
    X_encoded, y_log, test_size=0.4, random_state=42
)

X_val, X_test, y_val_log, y_test_log = train_test_split(
    X_temp, y_temp_log, test_size=0.5, random_state=42
)

y_train = np.expm1(y_train_log)
y_val = np.expm1(y_val_log)
y_test = np.expm1(y_test_log)

print(f"\nTraining: {X_train.shape[0]} samples")
print(f"Validation: {X_val.shape[0]} samples")
print(f"Test: {X_test.shape[0]} samples")

# Hyperparameter Optimization
param_grid = {
    'n_estimators': [300, 400, 500],
    'max_depth': [15, 20, 25, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [0.6, 0.8, None]
}

print("\nRunning hyperparameter optimization...")
grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42, n_jobs=-1),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=0
)

grid_search.fit(X_train, y_train_log)
print(f"Best parameters: {grid_search.best_params_}")

# Optimized Random Forest
best_rf = grid_search.best_estimator_
best_rf.fit(X_train, y_train_log)

# Predictions
y_train_pred_log = best_rf.predict(X_train)
y_val_pred_log = best_rf.predict(X_val)
y_test_pred_log = best_rf.predict(X_test)

y_train_pred = np.expm1(y_train_pred_log)
y_val_pred = np.expm1(y_val_pred_log)
y_test_pred = np.expm1(y_test_pred_log)

def print_metrics(y_true, y_pred, set_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    print(f"{set_name:12} MAE: ${mae:,.2f} | RMSE: ${rmse:,.2f} | R²: {r2:.4f}")
    return mae, rmse, r2

print("\nRANDOM FOREST PERFORMANCE:")
print("-" * 60)
train_mae, train_rmse, train_r2 = print_metrics(y_train, y_train_pred, "Training")
val_mae, val_rmse, val_r2 = print_metrics(y_val, y_val_pred, "Validation")
test_mae, test_rmse, test_r2 = print_metrics(y_test, y_test_pred, "Test")
print("-" * 60)

# Feature Importance
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_rf.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nTOP 10 FEATURES BY IMPORTANCE:")
print("-" * 45)
for i, row in importance_df.head(10).iterrows():
    print(f"{row['Feature']:25} {row['Importance']:.4f}")

plt.figure(figsize=(10, 6))
top_features = importance_df.head(15)
colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(top_features)))
bars = plt.barh(top_features['Feature'], top_features['Importance'], color=colors)
plt.xlabel('Importance Score')
plt.title('Random Forest Feature Importance')
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,
             f'{width:.3f}', ha='left', va='center')

plt.tight_layout()
plt.savefig('random_forest_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# Cross-Validation
cv_scores = cross_val_score(best_rf, X_train, y_train_log, 
                           cv=5, scoring='r2', n_jobs=-1)

print(f"\n5-FOLD CROSS-VALIDATION:")
print(f"Scores: {cv_scores.round(4)}")
print(f"Mean CV R²: {cv_scores.mean():.4f}")

# Visualizations
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].scatter(y_train, y_train_pred, alpha=0.5, color='blue', s=15)
max_val = max(y_train.max(), y_train_pred.max())
axes[0].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[0].set_xlabel('Actual Charges ($)')
axes[0].set_ylabel('Predicted Charges ($)')
axes[0].set_title(f'Training Set\nR² = {train_r2:.4f}')
axes[0].grid(True, alpha=0.3)

axes[1].scatter(y_val, y_val_pred, alpha=0.5, color='orange', s=15)
max_val = max(y_val.max(), y_val_pred.max())
axes[1].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[1].set_xlabel('Actual Charges ($)')
axes[1].set_ylabel('Predicted Charges ($)')
axes[1].set_title(f'Validation Set\nR² = {val_r2:.4f}')
axes[1].grid(True, alpha=0.3)

axes[2].scatter(y_test, y_test_pred, alpha=0.5, color='green', s=15)
max_val = max(y_test.max(), y_test_pred.max())
axes[2].plot([0, max_val], [0, max_val], 'r--', linewidth=2)
axes[2].set_xlabel('Actual Charges ($)')
axes[2].set_ylabel('Predicted Charges ($)')
axes[2].set_title(f'Test Set\nR² = {test_r2:.4f}')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('random_forest_predictions.png', dpi=300, bbox_inches='tight')
plt.show()

# Save Model
joblib.dump(best_rf, 'random_forest_model.pkl')
print("\nModel saved as 'random_forest_model.pkl'")

# Final Results
print("\n" + "=" * 60)
print("FINAL RESULTS")
print("=" * 60)
print(f"Test Set R² Score: {test_r2:.4f}")
print(f"Test Set MAE: ${test_mae:,.2f}")
print(f"Test Set RMSE: ${test_rmse:,.2f}")
print(f"5-Fold CV Mean R²: {cv_scores.mean():.4f}")
